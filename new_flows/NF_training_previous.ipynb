{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.utils.data as utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_RandD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_PureBkg = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mjj', 'Mj1', 'j1 tau21', 'j1 tau32', 'j1 tau43',\n",
       "       'j1 sqrt(tau^2_1)/tau^1_1', 'j1 n_trk', 'j1 pT1', 'j1 M_trim',\n",
       "       'j1 M_prun', 'j1 M_mmdt', 'j1 M_sdb1', 'j1 M_sdb2', 'j1 M_sdm1', 'Mj2',\n",
       "       'j2 tau21', 'j2 tau32', 'j2 tau43', 'j2 sqrt(tau^2_1)/tau^1_1',\n",
       "       'j2 n_trk', 'j2 pT1', 'j2 M_trim', 'j2 M_prun', 'j2 M_mmdt',\n",
       "       'j2 M_sdb1', 'j2 M_sdb2', 'j2 M_sdm1', 'isSignal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt_PureBkg = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt_PureBkg[:,27]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 1099997 1099998 1099999]\n"
     ]
    }
   ],
   "source": [
    "print(bkg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg[bkg_idx])\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "#total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "#total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "#total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_3),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 12])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PureBkg_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanarFlow(nn.Module):\n",
    "    def __init__(self, D):\n",
    "        super().__init__()\n",
    "        self.D = D\n",
    "\n",
    "    def forward(self, z, lamda):\n",
    "        '''\n",
    "        z - latents from prev layer\n",
    "        lambda - Flow parameters (b, w, u)\n",
    "        b - scalar\n",
    "        w - vector\n",
    "        u - vector\n",
    "        '''\n",
    "        b = lamda[:, :1]\n",
    "        w, u = lamda[:, 1:].chunk(2, dim=1)\n",
    "\n",
    "        # Forward\n",
    "        # f(z) = z + u tanh(w^T z + b)\n",
    "        transf = F.tanh(\n",
    "            z.unsqueeze(1).bmm(w.unsqueeze(2))[:, 0] + b\n",
    "        )\n",
    "        f_z = z + u * transf\n",
    "\n",
    "        # Inverse\n",
    "        # psi_z = tanh' (w^T z + b) w\n",
    "        psi_z = (1 - transf ** 2) * w\n",
    "        log_abs_det_jacobian = torch.log(\n",
    "            (1 + psi_z.unsqueeze(1).bmm(u.unsqueeze(2))).abs()\n",
    "        )\n",
    "\n",
    "        return f_z, log_abs_det_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList([PlanarFlow(D) for i in range(K)])\n",
    "\n",
    "    def forward(self, z_k, flow_params):\n",
    "        # ladj -> log abs det jacobian\n",
    "        sum_ladj = 0\n",
    "        for i, flow in enumerate(self.flows):\n",
    "            z_k, ladj_k = flow(z_k, flow_params[i])\n",
    "            sum_ladj += ladj_k\n",
    "\n",
    "        return z_k, sum_ladj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(12, 60),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(60, D * 2 + K * (D * 2 + 1))\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 60),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(60, 12),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.flows = NormalizingFlow(K, D)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "        flow_params = enc[:, 2 * self.dim:].chunk(self.K, dim=1)\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Construct more expressive posterior with NF\n",
    "        z_k, sum_ladj = self.flows(z, flow_params)\n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 2\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -58.0806 Time: 2.559 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -110.1818 Time: 2.941 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -119.5503 Time: 2.952 s\n",
      "Saving model!\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -118.6668 Time: 3.056 s\n",
      "Not saving model! Last saved: 3\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -115.9187 Time: 2.910 s\n",
      "Not saving model! Last saved: 3\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -117.8735 Time: 2.943 s\n",
      "Not saving model! Last saved: 3\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -121.7348 Time: 3.042 s\n",
      "Saving model!\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -122.6165 Time: 2.956 s\n",
      "Saving model!\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -122.9455 Time: 2.997 s\n",
      "Saving model!\n",
      "Epoch 10:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -123.2696 Time: 3.015 s\n",
      "Saving model!\n",
      "Epoch 11:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -124.6803 Time: 3.027 s\n",
      "Saving model!\n",
      "Epoch 12:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -126.2742 Time: 2.912 s\n",
      "Saving model!\n",
      "Epoch 13:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -128.4529 Time: 3.019 s\n",
      "Saving model!\n",
      "Epoch 14:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -130.7751 Time: 2.979 s\n",
      "Saving model!\n",
      "Epoch 15:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -131.9114 Time: 2.974 s\n",
      "Saving model!\n",
      "Epoch 16:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -133.8801 Time: 2.994 s\n",
      "Saving model!\n",
      "Epoch 17:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -136.0829 Time: 3.002 s\n",
      "Saving model!\n",
      "Epoch 18:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -137.0881 Time: 2.941 s\n",
      "Saving model!\n",
      "Epoch 19:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -137.8089 Time: 2.969 s\n",
      "Saving model!\n",
      "Epoch 20:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -138.5084 Time: 3.016 s\n",
      "Saving model!\n",
      "Epoch 21:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -138.6578 Time: 3.037 s\n",
      "Saving model!\n",
      "Epoch 22:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -138.9949 Time: 3.196 s\n",
      "Saving model!\n",
      "Epoch 23:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.3375 Time: 3.710 s\n",
      "Saving model!\n",
      "Epoch 24:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -138.9924 Time: 3.034 s\n",
      "Not saving model! Last saved: 23\n",
      "Epoch 25:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.2501 Time: 2.977 s\n",
      "Not saving model! Last saved: 23\n",
      "Epoch 26:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.1910 Time: 2.981 s\n",
      "Not saving model! Last saved: 23\n",
      "Epoch 27:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.7823 Time: 3.035 s\n",
      "Saving model!\n",
      "Epoch 28:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.7911 Time: 2.976 s\n",
      "Saving model!\n",
      "Epoch 29:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.0129 Time: 2.899 s\n",
      "Saving model!\n",
      "Epoch 30:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.5741 Time: 3.010 s\n",
      "Not saving model! Last saved: 29\n",
      "Epoch 31:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.7004 Time: 3.135 s\n",
      "Not saving model! Last saved: 29\n",
      "Epoch 32:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.0280 Time: 3.172 s\n",
      "Saving model!\n",
      "Epoch 33:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.9813 Time: 2.913 s\n",
      "Not saving model! Last saved: 32\n",
      "Epoch 34:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.3057 Time: 3.032 s\n",
      "Saving model!\n",
      "Epoch 35:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.2835 Time: 2.973 s\n",
      "Not saving model! Last saved: 34\n",
      "Epoch 36:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.6420 Time: 2.999 s\n",
      "Saving model!\n",
      "Epoch 37:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.4256 Time: 3.002 s\n",
      "Not saving model! Last saved: 36\n",
      "Epoch 38:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.0870 Time: 3.066 s\n",
      "Not saving model! Last saved: 36\n",
      "Epoch 39:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.4793 Time: 2.967 s\n",
      "Not saving model! Last saved: 36\n",
      "Epoch 40:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.2350 Time: 2.951 s\n",
      "Not saving model! Last saved: 36\n",
      "Epoch 41:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.0883 Time: 2.586 s\n",
      "Not saving model! Last saved: 36\n",
      "Epoch 42:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.2191 Time: 2.569 s\n",
      "Not saving model! Last saved: 36\n",
      "Patience Limit Reached\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "PATIENCE_COUNT = 0\n",
    "PATIENCE_LIMIT = 5\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        PATIENCE_COUNT = 0\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_previous_RND.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_previous_PureBkg.h5\")\n",
    "    else:\n",
    "        PATIENCE_COUNT += 1\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "        if PATIENCE_COUNT > 5:\n",
    "            print(\"Patience Limit Reached\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt_in):\n",
    "    \n",
    "    dt[:,0] = (dt[:,0]-np.mean(dt[:,0]))/np.std(dt[:,0])\n",
    "    dt[:,1] = (dt[:,1]-np.mean(dt[:,1]))/np.std(dt[:,1])\n",
    "    dt[:,2] = (dt[:,2]-np.mean(dt[:,2]))/np.std(dt[:,2])\n",
    "    dt[:,3] = (dt[:,3]-np.mean(dt[:,3]))/np.std(dt[:,3])\n",
    "    dt[:,4] = (dt[:,4]-np.mean(dt[:,4]))/np.std(dt[:,4])\n",
    "    dt[:,5] = (dt[:,5]-np.mean(dt[:,5]))/np.std(dt[:,5])\n",
    "\n",
    "    dt[:,7] = (dt[:,7]-np.mean(dt[:,7]))/np.std(dt[:,7])\n",
    "    dt[:,8] = (dt[:,8]-np.mean(dt[:,8]))/np.std(dt[:,8])\n",
    "    dt[:,9] = (dt[:,9]-np.mean(dt[:,9]))/np.std(dt[:,9])\n",
    "    dt[:,10] = (dt[:,10]-np.mean(dt[:,10]))/np.std(dt[:,10])\n",
    "    dt[:,11] = (dt[:,11]-np.mean(dt[:,11]))/np.std(dt[:,11])\n",
    "    dt[:,12] = (dt[:,12]-np.mean(dt[:,12]))/np.std(dt[:,12])\n",
    "\n",
    "  \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[0:6].t()\n",
    "    #total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[7:13].t()\n",
    "    #total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    #total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"/data/t3home000/spark//LHCOlympics_previous/LHC-Olympics/Code/Nsubjettiness_mjj.h5\")\n",
    "dt = f.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,15]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 1099997 1099998 1099999]\n"
     ]
    }
   ],
   "source": [
    "print(bkg_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = get_loss(dt[bkg_idx])\n",
    "loss_sig = get_loss(dt[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bkg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6820395  2.463571   0.4850646  ... 0.47974014 0.6829187  1.2222438 ]\n"
     ]
    }
   ],
   "source": [
    "print(loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1000)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
