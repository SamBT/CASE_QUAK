{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_available_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Number of available CPUs:\", num_available_cpus)\n",
    "\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../new_flows\")\n",
    "from flows import RealNVP, Planar, MAF\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.flows.autoregressive import MaskedAutoregressiveFlow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform, MaskedPiecewiseQuadraticAutoregressiveTransform, MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_available_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device =\", device)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor') if torch.cuda.is_available() else print ('cpu')\n",
    "\n",
    "torch.set_num_threads(num_available_cpus)\n",
    "\n",
    "print(torch.get_num_threads())\n",
    "print(torch.get_num_interop_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 12\n",
    "NS_hidden_features = 48\n",
    "flow_type = 'NSQUAD' #Options are 'MAF', 'Planar' (not recommended), 'NSQUAD', and 'NSRATQUAD'\n",
    "eta_cut = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdim = [4]\n",
    "nflow = [10]\n",
    "lrs = [1e-3]\n",
    "betas = [0.0,0.01,0.05,0.1,1.0]\n",
    "#betas = [0.1,0.5,1.0,2.0,10.0]\n",
    "#betas = [20.0,25.0,50.0,75.0,100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_result(object):\n",
    "    \n",
    "    def __init__(self, prefix, aetype):\n",
    "        self.sigloss = np.load(prefix+'_'+sigloss+'.npy')\n",
    "        self.bkgloss = np.load(prefix+'_'+bkgloss+'.npy')\n",
    "        self.aetype = aetype\n",
    "\n",
    "        \n",
    "    def get_tpr_fpr(self):\n",
    "        bins = np.linspace(0,10000,100001)\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "        for cut in bins:\n",
    "            if self.aetype == 'sig':\n",
    "                tpr.append(np.where(self.sigloss<cut)[0].shape[0]/len(self.sigloss))\n",
    "                fpr.append(np.where(self.bkgloss<cut)[0].shape[0]/len(self.bkgloss))\n",
    "            if self.aetype == 'bkg':\n",
    "                tpr.append(np.where(self.sigloss>cut)[0].shape[0]/len(self.sigloss))\n",
    "                fpr.append(np.where(self.bkgloss>cut)[0].shape[0]/len(self.bkgloss))\n",
    "        \n",
    "\n",
    "        return tpr,fpr\n",
    "    \n",
    "    def get_precision_recall(self):\n",
    "        bins = np.linspace(0,1000,10001)\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "        precision = []\n",
    "        for cut in bins:\n",
    "            if self.aetype == 'sig':\n",
    "                tpr.append(np.where(self.sigloss<cut)[0].shape[0]/len(self.sigloss))\n",
    "                precision.append((np.where(self.sigloss<cut)[0].shape[0])/(np.where(self.bkgloss<cut)[0].shape[0]+np.where(self.sigloss<cut)[0].shape[0]))\n",
    "            \n",
    "            if self.aetype == 'bkg':\n",
    "                tpr.append(np.where(self.sigloss>cut)[0].shape[0]/len(self.sigloss))\n",
    "                precision.append((np.where(self.sigloss>cut)[0].shape[0])/(np.where(self.bkgloss>cut)[0].shape[0]+np.where(self.sigloss>cut)[0].shape[0]))\n",
    "        \n",
    "\n",
    "        return precision,tpr  \n",
    "\n",
    "    def FPRat95TPR(self):\n",
    "        tprs, fprs = get_tpr_fpr(self)\n",
    "        for i in range(len(tprs)-1):\n",
    "            if (tprs[i] < 0.95) and (tprs[i+1] >= 0.95):\n",
    "                return fprs[i+1]\n",
    "\n",
    "    def FPRat99TPR(self):\n",
    "        tprs, fprs = get_tpr_fpr(self)\n",
    "        for i in range(len(tprs) - 1):\n",
    "            if (tprs[i] < 0.99) and (tprs[i + 1] >= 0.99):\n",
    "                return fprs[i+1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MAF / Planar / NSQUAD / NSRATQUAD\n",
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        \n",
    "        '''\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, 50),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(50, 30),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(20, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 20),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(30, 50),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(50, num_features)\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, 30),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(20, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 20),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(30, num_features)\n",
    "        )\n",
    "        \n",
    "        if flow_type == 'NSQUAD' or flow_type == 'NSRATQUAD': \n",
    "            #----- BEGIN NEW NEURAL SPLINE CODE\n",
    "            \n",
    "            bkg_transforms = []\n",
    "            for _ in range(K):\n",
    "                bkg_transforms.append(ReversePermutation(features=D))\n",
    "                if flow_type == 'NSQUAD': \n",
    "                    bkg_transforms.append(MaskedPiecewiseQuadraticAutoregressiveTransform(features=D, \n",
    "                                                                      hidden_features=NS_hidden_features, tail_bound = 3.0, tails='linear'))\n",
    "                elif flow_type == 'NSRATQUAD': \n",
    "                    bkg_transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(features=D, \n",
    "                                                                      hidden_features=NS_hidden_features, tail_bound = 3.0, tails='linear'))\n",
    "\n",
    "            #bkg_transform = CompositeTransform(bkg_transforms)\n",
    "            bkg_base_dist = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "            self.flows = NormalizingFlowModel(bkg_base_dist, bkg_transforms)\n",
    "            print(self.flows)\n",
    "            \n",
    "            #----- END NEW NEURAL SPLINE CODE\n",
    "        \n",
    "        elif flow_type == 'MAF' or flow_type == 'Planar': \n",
    "            if flow_type == 'MAF': \n",
    "                flow_init = MAF(dim=D)\n",
    "            elif flow_type == 'Planar': \n",
    "                flow_init = Planar(dim=D)\n",
    "            flows_init = [flow_init for _ in range(K)]\n",
    "            prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "            self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "            print(self.flows)\n",
    "        \n",
    "        else: \n",
    "            print('ERROR: Flow Type not properly specified.')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bkg_batches = 1\n",
    "num_sig_batches = 35\n",
    "\n",
    "Mjj_cut = 1200\n",
    "pt_cut = 550\n",
    "eta_cut = None\n",
    "box_cox = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_data = np.array([])\n",
    "\n",
    "for batch_number in range(num_bkg_batches): \n",
    "    train_batch = \"/nobackup/users/myunus/CASE_samples/BB_batch%s.h5\" % (batch_number)\n",
    "    f = h5py.File(train_batch, \"r\")\n",
    "    \n",
    "    if batch_number == 0: \n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "    \n",
    "    jet_kinematics = f['jet_kinematics']\n",
    "    jet1_extraInfo = f['jet1_extraInfo']\n",
    "    jet2_extraInfo = f['jet2_extraInfo']\n",
    "    truth_label = f['truth_label']\n",
    "\n",
    "    np.seterr(invalid = 'ignore')\n",
    "\n",
    "    delta_eta = jet_kinematics[:,1]\n",
    "\n",
    "    Mjj = np.reshape(jet_kinematics[:,0], (-1,1))\n",
    "    Mj1 = np.reshape(jet_kinematics[:,5], (-1,1))\n",
    "    Mj2 = np.reshape(jet_kinematics[:,9], (-1,1))\n",
    "\n",
    "    jet1_pt = np.reshape(jet_kinematics[:,2], (-1,1))\n",
    "    jet2_pt = np.reshape(jet_kinematics[:,6], (-1,1))\n",
    "\n",
    "    jet1_tau1 = np.reshape(jet1_extraInfo[:,0], (-1,1))\n",
    "    jet1_tau2 = np.reshape(jet1_extraInfo[:,1], (-1,1))\n",
    "    jet1_tau3 = np.reshape(jet1_extraInfo[:,2], (-1,1))\n",
    "    jet1_tau4 = np.reshape(jet1_extraInfo[:,3], (-1,1))\n",
    "    #jet1_btagscore = np.reshape(jet1_extraInfo[:,5],(-1,1))\n",
    "    jet1_numpfconst = np.reshape(jet1_extraInfo[:,6],(-1,1))\n",
    "\n",
    "    jet1_tau21 = jet1_tau2 / jet1_tau1\n",
    "    jet1_tau32 = jet1_tau3 / jet1_tau2\n",
    "    jet1_tau43 = jet1_tau4 / jet1_tau3\n",
    "    jet1_sqrt_tau21 = np.sqrt(jet1_tau21) / jet1_tau1\n",
    "\n",
    "    jet2_tau1 = np.reshape(jet2_extraInfo[:,0], (-1,1))\n",
    "    jet2_tau2 = np.reshape(jet2_extraInfo[:,1], (-1,1))\n",
    "    jet2_tau3 = np.reshape(jet2_extraInfo[:,2], (-1,1))\n",
    "    jet2_tau4 = np.reshape(jet2_extraInfo[:,3], (-1,1))\n",
    "    #jet2_btagscore = np.reshape(jet2_extraInfo[:,5],(-1,1))\n",
    "    jet2_numpfconst = np.reshape(jet2_extraInfo[:,6],(-1,1))\n",
    "\n",
    "    jet2_tau21 = jet2_tau2 / jet2_tau1\n",
    "    jet2_tau32 = jet2_tau3 / jet2_tau2\n",
    "    jet2_tau43 = jet2_tau4 / jet2_tau3\n",
    "    jet2_sqrt_tau21 = np.sqrt(jet2_tau21) / jet2_tau1\n",
    "\n",
    "    truth_label = truth_label[:]\n",
    "    \n",
    "    data = np.concatenate((Mj1, jet1_tau21, jet1_tau32, jet1_tau43, jet1_sqrt_tau21, jet1_numpfconst, \n",
    "                       Mj2, jet2_tau21, jet2_tau32, jet2_tau43, jet2_sqrt_tau21, jet2_numpfconst), axis=1)\n",
    "\n",
    "    bkg_indices = np.where((truth_label == 0) \n",
    "                              & (Mjj > Mjj_cut) \n",
    "                              & (jet1_pt > pt_cut) \n",
    "                              & (jet2_pt > pt_cut)\n",
    "                              & (np.isfinite(jet1_tau21))\n",
    "                              & (np.isfinite(jet1_tau32))\n",
    "                              & (np.isfinite(jet1_tau43))\n",
    "                              & (np.isfinite(jet1_sqrt_tau21))\n",
    "                              & (np.isfinite(jet2_tau21))\n",
    "                              & (np.isfinite(jet2_tau32))\n",
    "                              & (np.isfinite(jet2_tau43))\n",
    "                              & (np.isfinite(jet2_sqrt_tau21)))[0]\n",
    "\n",
    "    if eta_cut is not None:    \n",
    "        bkg_eta_indices = np.where((np.abs(delta_eta) < eta_cut))[0]     \n",
    "        bkg_indices = np.intersect1d(bkg_indices, bkg_eta_indices)\n",
    "\n",
    "    if batch_number == 0: \n",
    "        bkg_data = data[bkg_indices]\n",
    "\n",
    "    else: \n",
    "        bkg_data = np.concatenate((bkg_data, data[bkg_indices]), axis=0)\n",
    "        \n",
    "    if box_cox: \n",
    "        \n",
    "        transformed_data = np.zeros(bkg_data.shape)\n",
    "        best_lambdas = []\n",
    "        for col in range(num_features): \n",
    "            boxcox_col, best_lambda = stats.boxcox(bkg_data[:,col] + np.abs(np.min(bkg_data[:,col])) + 1)\n",
    "            transformed_data[:,col] = boxcox_col\n",
    "            best_lambdas.append(best_lambda)\n",
    "\n",
    "        print(best_lambdas)\n",
    "\n",
    "        bkg_data = transformed_data\n",
    "    \n",
    "print(bkg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_data = np.array([])\n",
    "\n",
    "for batch_number in range(num_sig_batches): \n",
    "    train_batch = \"/nobackup/users/myunus/CASE_samples/BB_batch%s.h5\" % (batch_number)\n",
    "    f = h5py.File(train_batch, \"r\")\n",
    "    \n",
    "    if batch_number == 0: \n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "    \n",
    "    jet_kinematics = f['jet_kinematics']\n",
    "    jet1_extraInfo = f['jet1_extraInfo']\n",
    "    jet2_extraInfo = f['jet2_extraInfo']\n",
    "    truth_label = f['truth_label']\n",
    "\n",
    "    np.seterr(invalid = 'ignore')\n",
    "\n",
    "    delta_eta = jet_kinematics[:,1]\n",
    "\n",
    "    Mjj = np.reshape(jet_kinematics[:,0], (-1,1))\n",
    "    Mj1 = np.reshape(jet_kinematics[:,5], (-1,1))\n",
    "    Mj2 = np.reshape(jet_kinematics[:,9], (-1,1))\n",
    "\n",
    "    jet1_pt = np.reshape(jet_kinematics[:,2], (-1,1))\n",
    "    jet2_pt = np.reshape(jet_kinematics[:,6], (-1,1))\n",
    "\n",
    "    jet1_tau1 = np.reshape(jet1_extraInfo[:,0], (-1,1))\n",
    "    jet1_tau2 = np.reshape(jet1_extraInfo[:,1], (-1,1))\n",
    "    jet1_tau3 = np.reshape(jet1_extraInfo[:,2], (-1,1))\n",
    "    jet1_tau4 = np.reshape(jet1_extraInfo[:,3], (-1,1))\n",
    "    #jet1_btagscore = np.reshape(jet1_extraInfo[:,5],(-1,1))\n",
    "    jet1_numpfconst = np.reshape(jet1_extraInfo[:,6],(-1,1))\n",
    "\n",
    "    jet1_tau21 = jet1_tau2 / jet1_tau1\n",
    "    jet1_tau32 = jet1_tau3 / jet1_tau2\n",
    "    jet1_tau43 = jet1_tau4 / jet1_tau3\n",
    "    jet1_sqrt_tau21 = np.sqrt(jet1_tau21) / jet1_tau1\n",
    "\n",
    "    jet2_tau1 = np.reshape(jet2_extraInfo[:,0], (-1,1))\n",
    "    jet2_tau2 = np.reshape(jet2_extraInfo[:,1], (-1,1))\n",
    "    jet2_tau3 = np.reshape(jet2_extraInfo[:,2], (-1,1))\n",
    "    jet2_tau4 = np.reshape(jet2_extraInfo[:,3], (-1,1))\n",
    "    #jet2_btagscore = np.reshape(jet2_extraInfo[:,5],(-1,1))\n",
    "    jet2_numpfconst = np.reshape(jet2_extraInfo[:,6],(-1,1))\n",
    "\n",
    "    jet2_tau21 = jet2_tau2 / jet2_tau1\n",
    "    jet2_tau32 = jet2_tau3 / jet2_tau2\n",
    "    jet2_tau43 = jet2_tau4 / jet2_tau3\n",
    "    jet2_sqrt_tau21 = np.sqrt(jet2_tau21) / jet2_tau1\n",
    "\n",
    "    truth_label = truth_label[:]\n",
    "    \n",
    "    data = np.concatenate((Mj1, jet1_tau21, jet1_tau32, jet1_tau43, jet1_sqrt_tau21, jet1_numpfconst, \n",
    "                       Mj2, jet2_tau21, jet2_tau32, jet2_tau43, jet2_sqrt_tau21, jet2_numpfconst), axis=1)\n",
    "    \n",
    "    sig_indices = np.where((truth_label == 2) \n",
    "                              & (Mjj > Mjj_cut) \n",
    "                              & (jet1_pt > pt_cut) \n",
    "                              & (jet2_pt > pt_cut)\n",
    "                              & (np.isfinite(jet1_tau21))\n",
    "                              & (np.isfinite(jet1_tau32))\n",
    "                              & (np.isfinite(jet1_tau43))\n",
    "                              & (np.isfinite(jet1_sqrt_tau21))\n",
    "                              & (np.isfinite(jet2_tau21))\n",
    "                              & (np.isfinite(jet2_tau32))\n",
    "                              & (np.isfinite(jet2_tau43))\n",
    "                              & (np.isfinite(jet2_sqrt_tau21)))[0]\n",
    "\n",
    "    if eta_cut is not None: \n",
    "        sig_eta_indices = np.copy(bkg_eta_indices)\n",
    "        sig_indices = np.intersect1d(sig_indices, sig_eta_indices)\n",
    "\n",
    "    if batch_number == 0: \n",
    "        sig_data = data[sig_indices]\n",
    "        \n",
    "    else: \n",
    "        sig_data = np.concatenate((sig_data, data[sig_indices]), axis=0)\n",
    "        \n",
    "    if box_cox: \n",
    "\n",
    "        transformed_data = np.zeros(sig_data.shape)\n",
    "        best_lambdas = []\n",
    "        for col in range(num_features): \n",
    "            boxcox_col, best_lambda = stats.boxcox(sig_data[:,col] + np.abs(np.min(sig_data[:,col])) + 1)\n",
    "            transformed_data[:,col] = boxcox_col\n",
    "            best_lambdas.append(best_lambda)\n",
    "\n",
    "        print(best_lambdas)\n",
    "    \n",
    "        sig_data = transformed_data\n",
    "    \n",
    "print(sig_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_bkg_data = np.copy(bkg_data)\n",
    "\n",
    "bkg_mean = []\n",
    "bkg_std = []\n",
    "\n",
    "for index in range(bkg_data.shape[1]):\n",
    "    mean = np.mean(bkg_data[:,index])\n",
    "    std = np.std(bkg_data[:,index])\n",
    "    bkg_mean.append(mean)\n",
    "    bkg_std.append(std)\n",
    "    bkg_data[:,index] = (bkg_data[:,index]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_sig_data = np.copy(sig_data)\n",
    "\n",
    "sig_mean = []\n",
    "sig_std = []\n",
    "\n",
    "for index in range(sig_data.shape[1]):\n",
    "    mean = np.mean(sig_data[:,index])\n",
    "    std = np.std(sig_data[:,index])\n",
    "    sig_mean.append(mean)\n",
    "    sig_std.append(std)\n",
    "    sig_data[:,index] = (sig_data[:,index]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_test = torch.tensor(bkg_data)\n",
    "sig_test = torch.tensor(sig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr_bkgtr(sigloss,bkgloss):\n",
    "    bins = np.linspace(0,100,10001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "        fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "\n",
    "    return tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprlist = []\n",
    "fprlist = []\n",
    "namelist = []\n",
    "bkgtr_siglosslist = []\n",
    "bkgtr_bkglosslist = []\n",
    "tprlist_forinverse = []\n",
    "fprinverselist = []\n",
    "\n",
    "for Z_DIM in zdim:\n",
    "    for N_FLOWS in nflow:\n",
    "        for beta in betas:\n",
    "            model = VAE_NF(N_FLOWS, Z_DIM).cuda()\n",
    "            #NOTE: The \"architecture\" key below can be set to \"MAF\", \"Planar\" (not recommended), \"NSQUAD\", or \"NSRATQUAD\". \n",
    "            ae_def = {\n",
    "                        \"type\":\"qcdbkg\",\n",
    "                        \"trainon\":f\"etacut{re.sub('[.,]', 'p', str(eta_cut))}\",\n",
    "                        \"features\":\"12features\",\n",
    "                        \"architecture\":\"%s\" % (flow_type),\n",
    "                        \"selection\":\"mjjcut\",\n",
    "                        \"trainloss\":\"MSELoss\",\n",
    "                        \"beta\":f\"beta{re.sub('[.,]', 'p', str(beta))}\",\n",
    "                        \"zdimnflow\":f\"z{Z_DIM}f{N_FLOWS}\"\n",
    "                     }\n",
    "            model.load_state_dict(torch.load(f\"/home/myunus/CASE/weights/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}.h5\"), strict=False)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                sig_loss = torch.mean((model(sig_test.float().cuda())[0]- sig_test.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "                bkg_loss = torch.mean((model(bkg_test.float().cuda())[0]- bkg_test.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "                #sig_loss = torch.mean((model(sig_test.float().cuda())[0]- sig_test.float().cuda())**2,dim=1).data.cpu().numpy() + beta * F.kl_div(model(sig_test.float().cuda())[0], sig_test.float().cuda()).cpu().numpy()\n",
    "                #bkg_loss = torch.mean((model(bkg_test.float().cuda())[0]- bkg_test.float().cuda())**2,dim=1).data.cpu().numpy() + beta * F.kl_div(model(bkg_test.float().cuda())[0], bkg_test.float().cuda()).cpu().numpy()\n",
    "                    \n",
    "            if beta == 1.0: \n",
    "                hi_loss_sig_indices = np.argwhere(sig_loss > 1).flatten()\n",
    "                lo_loss_sig_indices = np.argwhere(sig_loss < 1).flatten()\n",
    "                \n",
    "                hi_loss_sig_mj1 = unnorm_sig_data[hi_loss_sig_indices][:,0]\n",
    "                lo_loss_sig_mj1 = unnorm_sig_data[lo_loss_sig_indices][:,0]\n",
    "                \n",
    "                hi_loss_sig_mj2 = unnorm_sig_data[hi_loss_sig_indices][:,7]\n",
    "                lo_loss_sig_mj2 = unnorm_sig_data[lo_loss_sig_indices][:,7]\n",
    "                \n",
    "                plt.hist(sig_loss, bins=50)\n",
    "                plt.xlabel('sig loss (beta = 1.0)')\n",
    "                plt.show()\n",
    "\n",
    "                plt.hist(bkg_loss, bins=50)\n",
    "                plt.xlabel('bkg loss (beta = 1.0)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(hi_loss_sig_mj1, bins=50)\n",
    "                plt.xlabel('sig mj1 (loss > 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(lo_loss_sig_mj1, bins=50)\n",
    "                plt.xlabel('sig mj1 (loss < 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(hi_loss_sig_mj2, bins=50)\n",
    "                plt.xlabel('sig mj2 (loss > 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(lo_loss_sig_mj2, bins=50)\n",
    "                plt.xlabel('sig mj2 (loss < 1)')\n",
    "                plt.show()\n",
    "            \n",
    "            np.save(f\"/home/myunus/CASE/data_strings/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}_sigloss.npy\", sig_loss)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            np.save(f\"/home/myunus/CASE/data_strings/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}_bkgloss.npy\", bkg_loss)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            \n",
    "            namelist.append(ae_def)\n",
    "            tpr, fpr = get_tpr_fpr_bkgtr(sig_loss,bkg_loss)\n",
    "            tprlist.append(tpr)\n",
    "            fprlist.append(fpr)\n",
    "            tpr_np, fpr_np = np.array(tpr), np.array(fpr)\n",
    "            \n",
    "            nonzero_idx = np.nonzero(fpr_np)\n",
    "            \n",
    "            bkgtr_siglosslist.append(sig_loss)\n",
    "            bkgtr_bkglosslist.append(bkg_loss)\n",
    "            \n",
    "            tprlist_forinverse.append(tpr_np[nonzero_idx])\n",
    "            fprinverselist.append(1/fpr_np[nonzero_idx]) \n",
    "            \n",
    "            if beta == 0.01: \n",
    "                for plot_var in range(num_features):\n",
    "                    print(bkg_test.cpu().numpy().shape)\n",
    "                    print(model(bkg_test.float().cuda())[0].data.cpu().numpy().shape)\n",
    "                    n, bins, patches = plt.hist((bkg_test.cpu().numpy() * bkg_std + bkg_mean)[:,plot_var], bins = 50, density = True, alpha = 0.75)\n",
    "                    plt.hist((model(bkg_test.float().cuda())[0].data.cpu().numpy() * bkg_std + bkg_mean)[:,plot_var], bins = bins, density = True, alpha = 0.75)\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(betas)): \n",
    "        \n",
    "    bkgtr_bkgloss = bkgtr_bkglosslist[index]\n",
    "    bkgtr_sigloss = bkgtr_siglosslist[index]\n",
    "    \n",
    "    df_bkgloss = pd.DataFrame(bkgtr_bkgloss)\n",
    "    df_sigloss = pd.DataFrame(bkgtr_sigloss)\n",
    "    df_bkgloss.to_csv('csv_files/bkgtr_bkgloss_%s_%s_%s.csv' % (namelist[index]['trainon'], namelist[index]['architecture'], namelist[index]['beta'])) \n",
    "    df_sigloss.to_csv('csv_files/bkgtr_sigloss_%s_%s_%s.csv' % (namelist[index]['trainon'], namelist[index]['architecture'], namelist[index]['beta']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr, fpr, name,sigloss,bkgloss in zip(tprlist_forinverse,fprinverselist, namelist,bkgtr_siglosslist,bkgtr_bkglosslist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        #print(tpr, fpr)\n",
    "        plt.plot(tpr,fpr, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr,tpr))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "plt.ylabel(r'$1/\\epsilon_{bkg}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Background Prior')\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([0.0,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr, fpr, name,sigloss,bkgloss in zip(tprlist,fprlist, namelist,bkgtr_siglosslist,bkgtr_bkglosslist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        plt.plot(fpr,tpr, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr,tpr))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{bkg}$',fontsize=15)\n",
    "plt.ylabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlim([0.05,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr_sigtr(sigloss,bkgloss):\n",
    "    bins = np.linspace(0,100,10001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "        fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "\n",
    "    return tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprlist = []\n",
    "fprlist = []\n",
    "namelist = []\n",
    "sigtr_siglosslist = []\n",
    "sigtr_bkglosslist = []\n",
    "tprlist_forinverse = []\n",
    "fprinverselist = []\n",
    "\n",
    "for Z_DIM in zdim:\n",
    "    for N_FLOWS in nflow:\n",
    "        for beta in betas:\n",
    "            model = VAE_NF(N_FLOWS, Z_DIM).cuda()\n",
    "            #NOTE: The \"architecture\" key below can be set to \"MAF\", \"Planar\" (not recommended), \"NSQUAD\", or \"NSRATQUAD\". \n",
    "            ae_def = {\n",
    "                        \"type\":\"wprimesig\",\n",
    "                        \"trainon\":f\"etacut{re.sub('[.,]', 'p', str(eta_cut))}\",\n",
    "                        \"features\":\"12features\",\n",
    "                        \"architecture\":\"%s\" % (flow_type),\n",
    "                        \"selection\":\"mjjcut\",\n",
    "                        \"trainloss\":\"MSELoss\",\n",
    "                        \"beta\":f\"beta{re.sub('[.,]', 'p', str(beta))}\",\n",
    "                        \"zdimnflow\":f\"z{Z_DIM}f{N_FLOWS}\"\n",
    "                     }\n",
    "            model.load_state_dict(torch.load(f\"/home/myunus/CASE/weights/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}.h5\"), strict=False)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                sig_loss = torch.mean((model(sig_test.float().cuda())[0]- sig_test.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "                bkg_loss = torch.mean((model(bkg_test.float().cuda())[0]- bkg_test.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "                #sig_loss = torch.mean((model(sig_test.float().cuda())[0]- sig_test.float().cuda())**2,dim=1).data.cpu().numpy() + beta * F.kl_div(model(sig_test.float().cuda())[0], sig_test.float().cuda()).cpu().numpy()\n",
    "                #bkg_loss = torch.mean((model(bkg_test.float().cuda())[0]- bkg_test.float().cuda())**2,dim=1).data.cpu().numpy() + beta * F.kl_div(model(bkg_test.float().cuda())[0], bkg_test.float().cuda()).cpu().numpy()\n",
    "              \n",
    "            if beta == 1.0: \n",
    "                hi_loss_sig_indices = np.argwhere(sig_loss > 1).flatten()\n",
    "                lo_loss_sig_indices = np.argwhere(sig_loss < 1).flatten()\n",
    "                \n",
    "                hi_loss_sig_mj1 = unnorm_sig_data[hi_loss_sig_indices][:,0]\n",
    "                lo_loss_sig_mj1 = unnorm_sig_data[lo_loss_sig_indices][:,0]\n",
    "                \n",
    "                hi_loss_sig_mj2 = unnorm_sig_data[hi_loss_sig_indices][:,7]\n",
    "                lo_loss_sig_mj2 = unnorm_sig_data[lo_loss_sig_indices][:,7]\n",
    "                \n",
    "                plt.hist(sig_loss, bins=50, range=(0,10))\n",
    "                plt.xlabel('sig loss (beta = 1.0)')\n",
    "                plt.show()\n",
    "\n",
    "                plt.hist(bkg_loss, bins=50, range=(0,10))\n",
    "                plt.xlabel('bkg loss (beta = 1.0)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(hi_loss_sig_mj1, bins=50)\n",
    "                plt.xlabel('sig mj1 (loss > 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(lo_loss_sig_mj1, bins=50)\n",
    "                plt.xlabel('sig mj1 (loss < 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(hi_loss_sig_mj2, bins=50)\n",
    "                plt.xlabel('sig mj2 (loss > 1)')\n",
    "                plt.show()\n",
    "                \n",
    "                plt.hist(lo_loss_sig_mj2, bins=50)\n",
    "                plt.xlabel('sig mj2 (loss < 1)')\n",
    "                plt.show()\n",
    "                \n",
    "            np.save(f\"/home/myunus/CASE/data_strings/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}_sigloss.npy\", sig_loss)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            np.save(f\"/home/myunus/CASE/data_strings/{ae_def['type']}_{ae_def['trainon']}_{ae_def['features']}_{ae_def['architecture']}_{ae_def['selection']}_{ae_def['trainloss']}_{ae_def['beta']}_{ae_def['zdimnflow']}_bkgloss.npy\", bkg_loss)\n",
    "            #NOTE: Replace the /home/myunus/ above with the directory in which QUASAR resides.\n",
    "            \n",
    "            namelist.append(ae_def)\n",
    "            tpr, fpr = get_tpr_fpr_sigtr(sig_loss,bkg_loss)\n",
    "            tprlist.append(tpr)\n",
    "            fprlist.append(fpr)\n",
    "            tpr_np, fpr_np = np.array(tpr), np.array(fpr)\n",
    "            \n",
    "            nonzero_idx = np.nonzero(fpr_np)\n",
    "            \n",
    "            sigtr_siglosslist.append(sig_loss)\n",
    "            sigtr_bkglosslist.append(bkg_loss)\n",
    "            \n",
    "            tprlist_forinverse.append(tpr_np[nonzero_idx])\n",
    "            fprinverselist.append(1/fpr_np[nonzero_idx])        \n",
    "            \n",
    "            if beta == 0.01: \n",
    "                for plot_var in range(num_features):\n",
    "                    print(sig_test.cpu().numpy().shape)\n",
    "                    print(model(sig_test.float().cuda())[0].data.cpu().numpy().shape)\n",
    "                    n, bins, patches = plt.hist((sig_test.cpu().numpy() * sig_std + sig_mean)[:,plot_var], bins = 50, density = True, alpha = 0.75)\n",
    "                    plt.hist((model(sig_test.float().cuda())[0].data.cpu().numpy() * sig_std + sig_mean)[:,plot_var], bins = bins, density = True, alpha = 0.75)\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr, fpr, name,sigloss,bkgloss in zip(tprlist_forinverse,fprinverselist, namelist,sigtr_siglosslist,sigtr_bkglosslist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        #print(tpr, fpr)\n",
    "        plt.plot(tpr,fpr, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr,tpr))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "plt.ylabel(r'$1/\\epsilon_{bkg}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Background Prior')\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([0.0,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr, fpr, name,sigloss,bkgloss in zip(tprlist,fprlist, namelist,sigtr_siglosslist,sigtr_bkglosslist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        plt.plot(fpr,tpr, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr,tpr))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{bkg}$',fontsize=15)\n",
    "plt.ylabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlim([0.05,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D ROC Curves (Still in Development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def get_hull_coordinates(scan_tpr, scan_fpr):\n",
    "    points = np.array([scan_fpr,scan_tpr])\n",
    "    points = points.transpose()\n",
    "    hull = ConvexHull(points)\n",
    "    fpr = np.array(points[hull.vertices[:],0])\n",
    "    tpr = np.array(points[hull.vertices[:],1])\n",
    "    nonzero_idx = np.nonzero(fpr)\n",
    "    fpr = fpr[nonzero_idx]\n",
    "    tpr = tpr[nonzero_idx]\n",
    "    return tpr, fpr \n",
    "\n",
    "def get_tpr_fpr_2d(sigae_sigloss,sigae_bkgloss,bkgae_sigloss,bkgae_bkgloss):\n",
    "    bins_sigae = np.arange(0,30,0.1)\n",
    "    bins_bkgae = np.arange(0,30,0.1)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for sigcut in bins_sigae:\n",
    "        for bkgcut in bins_bkgae:\n",
    "            tpr_t = np.where((sigae_sigloss<sigcut)&(bkgae_sigloss>bkgcut))[0].shape[0]/len(sigae_sigloss)\n",
    "            fpr_t = np.where((sigae_bkgloss<sigcut)&(bkgae_bkgloss>bkgcut))[0].shape[0]/len(sigae_bkgloss)\n",
    "            tpr.append(tpr_t)\n",
    "            fpr.append(fpr_t)\n",
    "            \n",
    "    tpr, fpr = get_hull_coordinates(tpr, fpr)\n",
    "                \n",
    "\n",
    "    return tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr2dlist = []\n",
    "fpr2dlist = []\n",
    "tpr2dlist_forinverse = []\n",
    "fpr2dinverselist = []\n",
    "for SSLs, SBLs, BSLs, BBLs in zip(sigtr_siglosslist, sigtr_bkglosslist, bkgtr_siglosslist, bkgtr_bkglosslist):\n",
    "    print(SSLs[:20])\n",
    "    print(SBLs[:20])\n",
    "    print(BSLs[:20])\n",
    "    print(BBLs[:20])\n",
    "    tpr2d, fpr2d = get_tpr_fpr_2d(SSLs, SBLs, BSLs, BBLs)\n",
    "    print(tpr2d.shape)\n",
    "    print(fpr2d.shape)\n",
    "    tpr2dlist.append(tpr2d)\n",
    "    fpr2dlist.append(fpr2d)\n",
    "    tpr2d_np, fpr2d_np = np.array(tpr2d), np.array(fpr2d)\n",
    "\n",
    "    nonzero_idx = np.nonzero(fpr2d_np)\n",
    "\n",
    "    tpr2dlist_forinverse.append(tpr2d_np[nonzero_idx])\n",
    "    fpr2dinverselist.append(1/fpr2d_np[nonzero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr2d, fpr2d, name in zip(tpr2dlist_forinverse,fpr2dinverselist, namelist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        #print(tpr2d, fpr2d)\n",
    "        print(tpr2d.shape, fpr2d.shape)\n",
    "        plt.plot(tpr2d[1:],fpr2d[1:], label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #AUC Calculation below (buggy)\n",
    "        #print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr2d,tpr2d))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "plt.ylabel(r'$1/\\epsilon_{bkg}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Inverted 2D ROC')\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([0.0,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpr2d, fpr2d, name in zip(tpr2dlist,fpr2dlist, namelist):\n",
    "    #if name['beta'] == 'beta10p0' or name['beta'] == 'beta2p0':\n",
    "    if name['zdimnflow'] == 'z4f10':\n",
    "        plt.plot(fpr2d[1:],tpr2d[1:], label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #AUC calculation below (buggy)\n",
    "        #print(f\"{name['beta']}_{name['zdimnflow']}\",metrics.auc(fpr2d,tpr2d))\n",
    "        #plt.hist(sigloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "        #plt.hist(bkgloss,np.arange(0,10,0.1),alpha=0.2, density=True, label=f\"{name['beta']}_{name['zdimnflow']}\")\n",
    "plt.xlabel(r'$\\epsilon_{bkg}$',fontsize=15)\n",
    "plt.ylabel(r'$\\epsilon_{sig}$',fontsize=15)\n",
    "#plt.semilogy()\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlim([0.05,1.0])\n",
    "#plt.ylim([0.0,1.0])\n",
    "#plt.savefig('ROC_effectiveness_of_quak.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
