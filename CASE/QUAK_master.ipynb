{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_available_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Number of available CPUs:\", num_available_cpus)\n",
    "\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../new_flows\")\n",
    "from flows import RealNVP, Planar, MAF\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.flows.autoregressive import MaskedAutoregressiveFlow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform, MaskedPiecewiseQuadraticAutoregressiveTransform, MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device =\", device)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor') if torch.cuda.is_available() else print ('cpu')\n",
    "\n",
    "torch.set_num_threads(num_available_cpus)\n",
    "\n",
    "print(\"Number of threads:\", torch.get_num_threads())\n",
    "print(\"Number of interop threads:\", torch.get_num_interop_threads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 14\n",
    "hidden_features = 56\n",
    "\n",
    "num_layers = 4\n",
    "num_blocks_per_layer = 4\n",
    "#num_iter = 10000\n",
    "num_iter = 1000\n",
    "print_interval = 20\n",
    "\n",
    "#Current flow_type options: 'MAF', 'NSQUAD' (neural spline quadratic), 'NSRATQUAD' (neural spline rational quadratic)\n",
    "flow_type = 'NSQUAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Pure_NF_%s_k%s_hf%s_nbpl%s' % (flow_type, num_layers, hidden_features, num_blocks_per_layer)\n",
    "bkg_model = torch.load(\"pure_flows/bkg_%s.pt\" % (filename))\n",
    "sig_model = torch.load(\"pure_flows/sig_%s.pt\" % (filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bkg_batches = 1\n",
    "num_batches = 2    # for everything that isn't QCD background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_data, bkg_unnorm_data, bkg_masses = LAPS_test(sample_type = 'qcdbkg', num_batches = num_bkg_batches)\n",
    "print(bkg_data.shape)\n",
    "bkgtr_bkg_losses = -bkg_model.log_prob(bkg_data)[0].detach().cpu().numpy()\n",
    "sigtr_bkg_losses = -sig_model.log_prob(bkg_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_data, sig_unnorm_data, sig_masses = LAPS_test(sample_type = 'wprimesig', num_batches = num_batches)\n",
    "print(sig_data.shape)\n",
    "bkgtr_sig_losses = -bkg_model.log_prob(sig_data)[0].detach().cpu().numpy()\n",
    "sigtr_sig_losses = -sig_model.log_prob(sig_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graviton_data, graviton_unnorm_data, graviton_masses = LAPS_test(sample_type = 'graviton', num_batches = num_batches)\n",
    "print(graviton_data.shape)\n",
    "bkgtr_graviton_losses = -bkg_model.log_prob(graviton_data)[0].detach().cpu().numpy()\n",
    "sigtr_graviton_losses = -sig_model.log_prob(graviton_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wkk_data, Wkk_unnorm_data, Wkk_masses = LAPS_test(sample_type = 'Wkk', num_batches = num_batches)\n",
    "print(Wkk_data.shape)\n",
    "bkgtr_Wkk_losses = -bkg_model.log_prob(Wkk_data)[0].detach().cpu().numpy()\n",
    "sigtr_Wkk_losses = -sig_model.log_prob(Wkk_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wp2000_data, Wp2000_unnorm_data, Wp2000_masses = LAPS_test(sample_type = 'Wp2000', num_batches = num_batches)\n",
    "\n",
    "Wp2000_num_samples = Wp2000_data.shape[0]\n",
    "sampling_indices = np.random.randint(Wp2000_num_samples, size = int(0.05 * Wp2000_num_samples))\n",
    "Wp2000_data = Wp2000_data[sampling_indices, :]\n",
    "Wp2000_unnorm_data = Wp2000_unnorm_data[sampling_indices, :]\n",
    "Wp2000_masses = Wp2000_masses[sampling_indices, :]\n",
    "\n",
    "print(Wp2000_data.shape)\n",
    "bkgtr_Wp2000_losses = -bkg_model.log_prob(Wp2000_data)[0].detach().cpu().numpy()\n",
    "sigtr_Wp2000_losses = -sig_model.log_prob(Wp2000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wp3000_data, Wp3000_unnorm_data, Wp3000_masses = LAPS_test(sample_type = 'Wp3000', num_batches = num_batches)\n",
    "\n",
    "Wp3000_num_samples = Wp3000_data.shape[0]\n",
    "sampling_indices = np.random.randint(Wp3000_num_samples, size = int(0.05 * Wp3000_num_samples))\n",
    "Wp3000_data = Wp3000_data[sampling_indices, :]\n",
    "Wp3000_unnorm_data = Wp3000_unnorm_data[sampling_indices, :]\n",
    "Wp3000_masses = Wp3000_masses[sampling_indices, :]\n",
    "\n",
    "print(Wp3000_data.shape)\n",
    "bkgtr_Wp3000_losses = -bkg_model.log_prob(Wp3000_data)[0].detach().cpu().numpy()\n",
    "sigtr_Wp3000_losses = -sig_model.log_prob(Wp3000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wp5000_data, Wp5000_unnorm_data, Wp5000_masses = LAPS_test(sample_type = 'Wp5000', num_batches = num_batches)\n",
    "\n",
    "Wp5000_num_samples = Wp5000_data.shape[0]\n",
    "sampling_indices = np.random.randint(Wp5000_num_samples, size = int(0.05 * Wp5000_num_samples))\n",
    "Wp5000_data = Wp5000_data[sampling_indices, :]\n",
    "Wp5000_unnorm_data = Wp5000_unnorm_data[sampling_indices, :]\n",
    "Wp5000_masses = Wp5000_masses[sampling_indices, :]\n",
    "\n",
    "print(Wp5000_data.shape)\n",
    "bkgtr_Wp5000_losses = -bkg_model.log_prob(Wp5000_data)[0].detach().cpu().numpy()\n",
    "sigtr_Wp5000_losses = -sig_model.log_prob(Wp5000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSGraviton2000_data, RSGraviton2000_unnorm_data, RSGraviton2000_masses = LAPS_test(sample_type = 'RSGraviton2000', num_batches = num_batches)\n",
    "\n",
    "RSGraviton2000_num_samples = RSGraviton2000_data.shape[0]\n",
    "sampling_indices = np.random.randint(RSGraviton2000_num_samples, size = int(0.05 * RSGraviton2000_num_samples))\n",
    "RSGraviton2000_data = RSGraviton2000_data[sampling_indices, :]\n",
    "RSGraviton2000_unnorm_data = RSGraviton2000_unnorm_data[sampling_indices, :]\n",
    "RSGraviton2000_masses = RSGraviton2000_masses[sampling_indices, :]\n",
    "\n",
    "print(RSGraviton2000_data.shape)\n",
    "bkgtr_RSGraviton2000_losses = -bkg_model.log_prob(RSGraviton2000_data)[0].detach().cpu().numpy()\n",
    "sigtr_RSGraviton2000_losses = -sig_model.log_prob(RSGraviton2000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qstar2000_data, Qstar2000_unnorm_data, Qstar2000_masses = LAPS_test(sample_type = 'Qstar2000', num_batches = num_batches)\n",
    "\n",
    "Qstar2000_num_samples = Qstar2000_data.shape[0]\n",
    "sampling_indices = np.random.randint(Qstar2000_num_samples, size = int(0.05 * Qstar2000_num_samples))\n",
    "Qstar2000_data = Qstar2000_data[sampling_indices, :]\n",
    "Qstar2000_unnorm_data = Qstar2000_unnorm_data[sampling_indices, :]\n",
    "Qstar2000_masses = Qstar2000_masses[sampling_indices, :]\n",
    "\n",
    "print(Qstar2000_data.shape)\n",
    "bkgtr_Qstar2000_losses = -bkg_model.log_prob(Qstar2000_data)[0].detach().cpu().numpy()\n",
    "sigtr_Qstar2000_losses = -sig_model.log_prob(Qstar2000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wkk2000_data, Wkk2000_unnorm_data, Wkk2000_masses = LAPS_test(sample_type = 'Wkk2000', num_batches = num_batches)\n",
    "\n",
    "Wkk2000_num_samples = Wkk2000_data.shape[0]\n",
    "sampling_indices = np.random.randint(Wkk2000_num_samples, size = int(0.05 * Wkk2000_num_samples))\n",
    "Wkk2000_data = Wkk2000_data[sampling_indices, :]\n",
    "Wkk2000_unnorm_data = Wkk2000_unnorm_data[sampling_indices, :]\n",
    "Wkk2000_masses = Wkk2000_masses[sampling_indices, :]\n",
    "\n",
    "print(Wkk2000_data.shape)\n",
    "bkgtr_Wkk2000_losses = -bkg_model.log_prob(Wkk2000_data)[0].detach().cpu().numpy()\n",
    "sigtr_Wkk2000_losses = -sig_model.log_prob(Wkk2000_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master QUAK Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bkgtr_bkg_losses, sigtr_bkg_losses, s=2, label = 'Bkg samples')\n",
    "plt.scatter(bkgtr_sig_losses, sigtr_sig_losses, s=2, label = 'W\\' sig samples')\n",
    "#plt.scatter(bkgtr_graviton_losses, sigtr_graviton_losses, s=2, label = 'Graviton sig samples')\n",
    "#plt.scatter(bkgtr_Wkk_losses, sigtr_Wkk_losses, s=2, label = 'Wkk sig samples')\n",
    "plt.scatter(bkgtr_Wp2000_losses, sigtr_Wp2000_losses, s=2, label = 'Wp2000 sig samples')\n",
    "plt.scatter(bkgtr_Wp3000_losses, sigtr_Wp3000_losses, s=2, label = 'Wp3000 sig samples')\n",
    "plt.scatter(bkgtr_Wp5000_losses, sigtr_Wp5000_losses, s=2, label = 'Wp5000 sig samples')\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"BKG-Trained Model Loss\")\n",
    "plt.ylabel(\"SIG-Trained Model Loss\")\n",
    "plt.title(\"Synthetic Testing Data QUAK Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bkgtr_bkg_losses, sigtr_bkg_losses, s=2, label = 'Bkg samples')\n",
    "plt.scatter(bkgtr_sig_losses, sigtr_sig_losses, s=2, label = 'W\\' sig samples')\n",
    "#plt.scatter(bkgtr_graviton_losses, sigtr_graviton_losses, s=2, label = 'Graviton sig samples')\n",
    "#plt.scatter(bkgtr_Wkk_losses, sigtr_Wkk_losses, s=2, label = 'Wkk sig samples')\n",
    "plt.scatter(bkgtr_RSGraviton2000_losses, sigtr_RSGraviton2000_losses, s=2, label = 'RSGraviton2000 sig samples')\n",
    "plt.scatter(bkgtr_Qstar2000_losses, sigtr_Qstar2000_losses, s=2, label = 'Qstar2000 sig samples')\n",
    "plt.scatter(bkgtr_Wp5000_losses, sigtr_Wp5000_losses, s=2, label = 'Wp2000 sig samples')\n",
    "plt.scatter(bkgtr_Wkk2000_losses, sigtr_Wkk2000_losses, s=2, label = 'Wkk2000 sig samples')\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"BKG-Trained Model Loss\")\n",
    "plt.ylabel(\"SIG-Trained Model Loss\")\n",
    "plt.title(\"Synthetic Testing Data QUAK Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
