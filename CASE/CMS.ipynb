{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_available_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Number of available CPUs:\", num_available_cpus)\n",
    "\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../new_flows\")\n",
    "from flows import RealNVP, Planar, MAF\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.flows.autoregressive import MaskedAutoregressiveFlow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform, MaskedPiecewiseQuadraticAutoregressiveTransform, MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device =\", device)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor') if torch.cuda.is_available() else print ('cpu')\n",
    "\n",
    "torch.set_num_threads(num_available_cpus)\n",
    "\n",
    "print(\"Number of threads:\", torch.get_num_threads())\n",
    "print(\"Number of interop threads:\", torch.get_num_interop_threads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 14\n",
    "hidden_features = 56\n",
    "\n",
    "num_layers = 4\n",
    "num_blocks_per_layer = 4\n",
    "#num_iter = 10000\n",
    "num_iter = 1000\n",
    "print_interval = 20\n",
    "\n",
    "#Current flow_type options: 'MAF', 'NSQUAD' (neural spline quadratic), 'NSRATQUAD' (neural spline rational quadratic)\n",
    "flow_type = 'NSQUAD'\n",
    "\n",
    "study = 'BB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Pure_NF_%s_k%s_hf%s_nbpl%s' % (flow_type, num_layers, hidden_features, num_blocks_per_layer)\n",
    "\n",
    "if study == 'BB': \n",
    "    bkg_model = torch.load(\"pure_flows/bkg_%s.pt\" % (filename))\n",
    "    sig_model = torch.load(\"pure_flows/sig_%s.pt\" % (filename))\n",
    "else: \n",
    "    bkg_model = torch.load(\"new_sample_flows/%s/bkg_%s.pt\" % (study, filename))\n",
    "    sig_model = torch.load(\"new_sample_flows/%s/sig_%s.pt\" % (study, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bkg_batches = 2\n",
    "num_batches = 111\n",
    "sampling_percentage = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_data, bkg_unnorm_data, bkg_masses = LAPS_test(sample_type = 'qcdbkg', num_batches = num_bkg_batches)\n",
    "print(bkg_data.shape)\n",
    "bkg_mean = np.mean(bkg_unnorm_data, axis=0)\n",
    "bkg_std = np.std(bkg_unnorm_data, axis=0)\n",
    "\n",
    "bkgtr_bkg_losses = -bkg_model.log_prob(bkg_data)[0].detach().cpu().numpy()\n",
    "sigtr_bkg_losses = -sig_model.log_prob(bkg_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_data, CMS_unnorm_data, CMS_masses = LAPS_test_CMS(num_batches = num_batches, inp_meanstd = (bkg_mean, bkg_std))\n",
    "\n",
    "CMS_num_samples = CMS_data.shape[0]\n",
    "sampling_indices = np.random.randint(CMS_num_samples, size = int(sampling_percentage * CMS_num_samples / 100))\n",
    "CMS_data = CMS_data[sampling_indices, :]\n",
    "CMS_unnorm_data = CMS_unnorm_data[sampling_indices, :]\n",
    "CMS_masses = CMS_masses[sampling_indices, :]\n",
    "\n",
    "print(CMS_data.shape)\n",
    "bkgtr_CMS_losses = -bkg_model.log_prob(CMS_data)[0].detach().cpu().numpy()\n",
    "sigtr_CMS_losses = -sig_model.log_prob(CMS_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_mj1 = CMS_unnorm_data[:,0]\n",
    "CMS_mj2 = CMS_unnorm_data[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mass = pd.DataFrame(np.ndarray.tolist(CMS_masses))\n",
    "df_mass = pd.DataFrame(np.ndarray.tolist(CMS_mj1))    # FOR TTBAR SEARCH\n",
    "#df_mass = pd.DataFrame(np.ndarray.tolist(CMS_mj2))    # FOR TTBAR SEARCH\n",
    "\n",
    "df_mass.to_csv('csv_files/CMS_masses.csv')\n",
    "\n",
    "df_bkgloss = pd.DataFrame(np.ndarray.tolist(bkgtr_CMS_losses))\n",
    "df_bkgloss.to_csv('csv_files/bkgtr_CMS_losses.csv')\n",
    "\n",
    "df_sigloss = pd.DataFrame(np.ndarray.tolist(sigtr_CMS_losses))\n",
    "df_sigloss.to_csv('csv_files/sigtr_CMS_losses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master QUAK Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bad_loss_cutoff = 100\n",
    "y_bad_loss_cutoff = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_bkgtr_CMS_losses = np.append(bkgtr_CMS_losses, np.array([0,]))\n",
    "temp_sigtr_CMS_losses = np.append(sigtr_CMS_losses, np.array([0,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bkgtr_CMS_losses, sigtr_CMS_losses, s=2, label = '13 TeV CMS data')\n",
    "plt.xlim(0, x_bad_loss_cutoff)\n",
    "plt.ylim(0, y_bad_loss_cutoff)\n",
    "plt.xlabel('QCD Bkg Model Loss')\n",
    "#plt.ylabel(r'''W'$\\rightarrow$tB' (M=2000) Sig Model Loss''')\n",
    "plt.ylabel(r'''W'$\\rightarrow$WZ Sig Model Loss''')\n",
    "plt.title('Testing Data QUAK Space (Scatter Plot)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 2000\n",
    "\n",
    "h_bkg, bkg_xedges, bkg_yedges, _ = plt.hist2d(temp_bkgtr_CMS_losses, temp_sigtr_CMS_losses, cmap = plt.cm.jet, bins=num_bins)\n",
    "plt.colorbar()\n",
    "plt.xlabel('QCD Bkg Model Loss')\n",
    "plt.ylabel(r'''W'$\\rightarrow$WZ Sig Model Loss''')\n",
    "plt.title('Testing Data QUAK Space (Heat Map)')\n",
    "plt.xlim(0, x_bad_loss_cutoff)\n",
    "plt.ylim(0, y_bad_loss_cutoff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Input Variable Density Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study == 'BB': \n",
    "    num_sig_batches = 5\n",
    "else: \n",
    "    num_sig_batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_data, sig_unnorm_data, sig_masses = LAPS_test(sample_type = 'wprimesig', num_batches = num_sig_batches, inp_meanstd = (bkg_mean, bkg_std))\n",
    "\n",
    "sig_num_samples = sig_data.shape[0]\n",
    "if study == 'BB': \n",
    "    sampling_indices = np.random.randint(sig_num_samples, size = int(0.158 * sig_num_samples))\n",
    "else: \n",
    "    sampling_indices = np.random.randint(sig_num_samples, size = int(0.05 * sig_num_samples))\n",
    "\n",
    "sig_data = sig_data[sampling_indices, :]\n",
    "sig_unnorm_data = sig_unnorm_data[sampling_indices, :]\n",
    "sig_masses = sig_masses[sampling_indices, :]\n",
    "\n",
    "print(sig_data.shape)\n",
    "bkgtr_sig_losses = -bkg_model.log_prob(sig_data)[0].detach().cpu().numpy()\n",
    "sigtr_sig_losses = -sig_model.log_prob(sig_data)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_titles = [r'$M_{j1}$', r'Jet 1 $\\tau_{21}$', r'Jet 1 $\\tau_{32}$', r'Jet 1 $\\tau_{43}$', r'Jet 1 $\\tau_s$', r'Jet 1 $P_b$', r'Jet 1 $n_{pf}$', \n",
    "              r'$M_{j2}$', r'Jet 2 $\\tau_{21}$', r'Jet 2 $\\tau_{32}$', r'Jet 2 $\\tau_{43}$', r'Jet 2 $\\tau_s$', r'Jet 2 $P_b$', r'Jet 2 $n_{pf}$',]\n",
    "\n",
    "for index in range(num_features): \n",
    "    n, bins, patches = plt.hist(bkg_data[:, index], bins=30, histtype='step', density=True, label='QCD bkg samples')\n",
    "    plt.hist(sig_data[:, index], bins=bins, histtype='step', density=True, label=r'''W'$\\rightarrow$WZ sig samples''')\n",
    "    plt.hist(CMS_data[:, index], bins=bins, histtype='step', density=True, label='13 TeV CMS data')\n",
    "    if index % 7 == 4: \n",
    "        plt.legend(loc=(1.04,0.73))\n",
    "    plt.title(plot_titles[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
